{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 : Séparateurs à Vaste Marge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_breastcancer(filename):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename, par exemple\n",
    "    filename = 'wdbc_M1_B0.data'\n",
    "    Elle retourne \n",
    "    X : une matrice de caracteristiques\n",
    "    y : un vecteur des classes tel que si y[i] = 1, la tumeur est maligne\n",
    "        et si y[i] = -1, la tumeur est benigne\n",
    "\n",
    "    Pour plus d'infos sur la base de donnees,\n",
    "    https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "\n",
    "    # la colonne 0 ne nous interesse pas ici\n",
    "    y = data[:, 1] * 2 - 1\n",
    "    X = data[:, 2:]\n",
    "\n",
    "    # Standardisation de la matrice\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    X = X / np.std(X, axis=0)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breastcancer(\"wdbcM1B0.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ Méthode du sous-gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.1/\n",
    "Soit $\\Xi_i (v,a) = [max(0, 1-y_i(x_i^T v+ a); + \\infty[$\n",
    "\n",
    "Soit $\\Xi (v,a) = \\prod_i \\Xi_i (v,a)$\n",
    "\n",
    "$\\forall$ $v \\in R_m$, $a \\in R$, $\\xi \\in \\Xi (v,a)$, $\\space$ soit $f(v, a, \\xi) = \\frac{1}{2} \\sum_j v_j^2 + \\sum_i \\xi_i$. $f$ est une fonction croissante de $\\xi_i \\, \\forall i$ (et pour tout $v, a, \\xi_j (j\\ne i)$  fixés).\n",
    "\n",
    "Soit $\\xi_{min} = (\\xi_{{min}_i})_i$ avec $\\xi_{min_i} = max(0, 1-y_i(x_i^T v+ a)$\n",
    "\n",
    "Alors on a $\\forall$ $v \\in R_m$, $a \\in R$, $\\xi \\in \\Xi (v,a)$, $f(v, a, \\xi) \\ge f(v, a, \\xi_{min})$. (Parce que $f$ est croissante pour $\\xi_i \\space \\forall i$.)\n",
    "\n",
    "Donc, $min_{v,a,\\xi} f(v,a,\\xi) \\ge min_{v,a,\\xi} f(v, a, \\xi_{min}) = min_{v,a} f(v, a, \\xi_{min})$\n",
    "\n",
    "On a donc la première inegalité : $min_{v,a,\\xi} f(v,a,\\xi) \\ge min_{v,a} f(v, a, \\xi_{min})$\n",
    "\n",
    "De plus, pour toute fonction $g$ a deux variables admettant un minimum, $\\forall b_o \\in B, min_{a\\in A, b \\in B} g(a,b) \\le min_{a \\in A} g(a,b_o)$ \n",
    "\n",
    "Avec $g = f$ et $\\xi_o = \\xi_{min}$, $min_{v,a,\\xi} f(v,a,\\xi) \\le min_{v,a} f(v, a, \\xi_{min})$\n",
    "\n",
    "\n",
    "En conclusion on a bien équivalence entre les deux problèmes.\n",
    "\n",
    "Et on peut définir $f(v, a) = f(v, a, \\xi_{min})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def h(z):\n",
    "    return np.maximum(np.zeros(z.shape),1-z)\n",
    "\n",
    "z = np.arange(-8,12,0.01)\n",
    "plt.plot(z, h(z), color = 'blue', label = \"h(z)\")\n",
    "plt.plot([-8,12], [-0.2,-.2], color = 'orange', label = \"sub_diff(h, 1)\")\n",
    "plt.plot([-8,12], [8.8, -11.2], color = 'orange')\n",
    "plt.plot([-8,12], [4.3, -5.7], color = 'orange')\n",
    "plt.plot([-8,12], [9*3/4-0.2,-11*3/4 -0.2], color = 'orange')\n",
    "plt.plot([-8,12], [9/4-0.2,-11/4 -0.2], color = 'orange')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h est dérivable pourr z != 1. Donc pour z !=1, $\\partial h(z) = \\frac{dh}{dz} (z)$.\n",
    "\n",
    "Et pour z = 1, on remarque avec la représentation que toute les pentes entre -1 et 0 conviennent\n",
    "\n",
    "Donc $\\partial h(z) = \\left \\{\n",
    "\\begin{array} {}\n",
    "    \\{-1\\} & if \\, z \\lt 1 \\\\\n",
    "    [-1;0] & if \\, z = 1 \\\\\n",
    "    \\{0\\} & if \\, z \\gt 1 \\\\\n",
    "\\end{array}\n",
    "\\right .$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $N(w) = \\sum_{j=1}^{m+1} N_j(w_j)$. With $\\forall j \\in [1;m], N_j(w_j) = \\frac{1}{2}w_j^2$ and $N_{m+1} = 0$. N est separable.\n",
    "\n",
    "Et avec $w = (v,a), N(v,a) = \\frac{1}{2}\\sum_j v_j^2$.\n",
    "\n",
    "Soit $M = \n",
    "\\begin{pmatrix}\n",
    "y_{1} & &0 \\\\\n",
    "& \\ddots & \\\\\n",
    "0 & & y_{n}\n",
    "\\end{pmatrix} \\times \\begin{pmatrix} \n",
    "X, &  \\begin{pmatrix} 1\\\\\\vdots\\\\1 \\end{pmatrix}\n",
    "\\end{pmatrix} \\in M_{n,m+1}(R)$\n",
    "\n",
    "$M \\begin{pmatrix} v\\\\a \\end{pmatrix} = \\begin{pmatrix}y_0(x_0^Tv + a)\\\\ \\vdots \\\\ y_n(x_n^Tv +a) \\end{pmatrix}$\n",
    "\n",
    "Puis posons $H(x) = \\sum_{i=1}^n h(x_i)$. With $h(z) = max(0,1-z)$. H est separable.\n",
    "\n",
    "Et $H(M(v,a)) = \\sum_i max(0, 1-y_i(x_i^Tv +a))$ et donc $f(v,a) = N(v,a) + cH(M(v,a))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus on a $0 \\in r_i(Mdom(N) - dom(H))$ puisque $dom(N) = R_m$.\n",
    "\n",
    "Donc $\\partial f(v,a) = \\partial N(v,a) + cM^T \\partial H (M(v,a)).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N est derivalbe donc $\\partial N(v,a) = (v, 0)$\n",
    "\n",
    "Et H est separable donc $\\partial H(M(v,a)) = \\prod_i \\partial h(M_i(v,a)) = \\prod_i \\partial h(y_i(x_i^Tv+a))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "M = np.dot(np.diag(y), np.concatenate([X, np.ones((569,1))], axis = 1))\n",
    "def N(va):\n",
    "    return 0.5 * np.sum(va[:-1]**2)\n",
    "def H_M(va):\n",
    "    return np.sum(h(np.dot(M,va)))\n",
    "\n",
    "def f(va):\n",
    "    return N(va) + c * H_M(va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_N(va):\n",
    "    return np.concatenate([va[:-1], [0]])\n",
    "\n",
    "def delta_H_M(va):\n",
    "    \"\"\"Return one element of M^T x delta_H(M(v,a))\"\"\"\n",
    "    return np.dot(M.T, (np.dot(M,va)>=1)- 1)\n",
    "\n",
    "def delta_f(va):\n",
    "    return delta_N(va) + c * delta_H_M(va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2.5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_grad_method(va0, N):\n",
    "    va_moy = np.zeros(va0.shape)\n",
    "    gamma_sum = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        #Pour optimiser la convergence j'ai choisi de ne pas prendre le gamma\n",
    "        #proposé par l'énoncé. (Il donne trop d'importance au premier terme et convergence en 1/log(N))\n",
    "        #Ici j'ai une convergence en log(N)/sqrt(N) cf le poly\n",
    "        gamma = 0.001/np.sqrt(i+1)\n",
    "        gamma_sum += gamma\n",
    "        va_moy += va0 * gamma\n",
    "        \n",
    "        va0 = va0 - gamma*delta_f(va0)\n",
    "    \n",
    "    return va_moy/gamma_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569.0\n",
      "28.087767544895126\n"
     ]
    }
   ],
   "source": [
    "va0 = np.zeros((31,))\n",
    "print(f(va0))\n",
    "va_1 = sub_grad_method(va0, 100000)\n",
    "print(f(va_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Méthode du sous-gradient stochastique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.1/\n",
    "On a:\n",
    "\n",
    "$\\begin{array}{}\n",
    "E(f_I(v,a)) = \\sum_i P(I = i) \\times f_i(v,a) \\\\\n",
    "E(f_I(v,a)) = \\frac{1}{n}\\sum_i f_i(v,a) \\\\\n",
    "E(f_I(v,a)) = \\frac{1}{2} \\sum_j v_j^2 + \\frac{1}{n}\\sum_i c\\,n\\,max(0,1-y_i(x_i^Tv + a))\\\\\n",
    "E(f_I(v,a)) = \\frac{1}{2} \\sum_j v_j^2 + c\\sum_i max(0,1-y_i(x_i^Tv + a))\\\\ \n",
    "E(f_I(v,a)) = f(v,a)\\\\\n",
    "\\end{array}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $M_i = y_i(x_i^T, 1)$. $M_i\\begin{pmatrix} v \\\\ a \\\\ \\end{pmatrix} = y_i(x_i^Tv + a)$. \n",
    "(On peut remarquer que $M_i$ est la $i^{eme}$ ligne de M)\n",
    "\n",
    "\n",
    "On a :$f_i(v,a) = N(v,a) + c \\times n \\times h(M_i(v,a))$\n",
    "\n",
    "Donc : $\\partial f_i(v,a) = (v,0) + c\\times n\\times M_i^T\\partial h(M_i(v,a))$\n",
    "\n",
    "$\\partial f_i(v,a) = \\left \\{\n",
    "\\begin{array} {}\n",
    "    \\{(v,0) - ncM_i^T\\} & if \\, M_i(v,a) \\lt 1 \\\\\n",
    "    \\{(v,0) + tncM_i^t,\\,t \\in [-1;0]\\} & if \\, M_i(v,a) = 1 \\\\\n",
    "    \\{(v,0)\\} & if \\, M_i(v,a) \\gt 1 \\\\\n",
    "\\end{array}\n",
    "\\right .$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_h_M_i(va, i):\n",
    "    return ((np.dot(M[i,:],va)>=1)- 1) * M[i,:]\n",
    "\n",
    "def delta_f_i(va, i):\n",
    "    return delta_N(va) + c * M.shape[0] * delta_h_M_i(va,i)\n",
    "\n",
    "def stoch_grad_method(va0, N):\n",
    "    n = M.shape[0]\n",
    "    va_moy = np.zeros(va0.shape)\n",
    "    gamma_sum = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        I = np.random.randint(n)\n",
    "        gamma = 0.001/np.sqrt(i+1)\n",
    "        gamma_sum += gamma\n",
    "        va_moy += va0 * gamma\n",
    "        \n",
    "        va0 = va0 - gamma * delta_f_i(va0,I)\n",
    "    \n",
    "    #return va0\n",
    "    return va_moy/gamma_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.10187405578579"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_2 = stoch_grad_method(va0,100000)\n",
    "f(va_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/ Méthode du lagrangien augmenté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le lagrangien du probleme 1 s'écrit  pour $(v,a,\\xi, \\phi) \\in R_m \\times R \\times R_n \\times R_n$  :\n",
    "$L(v, a, \\xi, \\phi) = \\frac{1}{2} \\sum_jv_j^2 + c\\sum_i\\xi_i + \\sum_i\\phi_i \\times (1-M_i(v,a)-\\xi_i) + \\sum_i \\iota_{R_+}(\\phi_i)$\n",
    "\n",
    "$L(v, a, \\xi, \\phi) = \\frac{1}{2} \\sum_jv_j^2 + \\sum_i[c\\xi_i + \\phi_i \\times (1-M_i(v,a)-\\xi_i) + \\iota_{R_+}(\\phi_i)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessons nous d'abord à g comme fonction de x pour tout $\\phi$.\n",
    "\n",
    "On a deja : $g(\\cdot,\\phi) \\in C^0(R)$. De plus, $\\forall x \\gt -\\frac{\\phi}{\\rho},\\, g(x, \\phi) = \\frac{\\rho x^2}{2} + x\\phi$\n",
    "\n",
    "Donc pour $\\forall x \\gt -\\frac{\\phi}{\\rho},\\, g(\\cdot, \\phi)$ est derivable et sa dérivée vaut $\\nabla_xg(x, \\phi) = \\rho x+ \\phi$\n",
    "\n",
    "Et, $\\forall x \\lt -\\frac{\\phi}{\\rho},\\, g(x, \\phi) = -\\frac{\\phi^2}{2 \\rho}$ Donc pour $\\forall x \\lt -\\frac{\\phi}{\\rho},\\, g(\\cdot, \\phi)$ est derivable et sa dérivée vaut $\\nabla_xg(x, \\phi) = 0$\n",
    "\n",
    "Finalement, on peut observer que $\\underset{x\\to-\\frac{\\phi}{\\rho}, x \\lt -\\frac{\\phi}{\\rho}}{\\lim}(\\nabla_xg(x,\\phi)$ = $\\underset{x\\to-\\frac{\\phi}{\\rho}, x \\gt -\\frac{\\phi}{\\rho}}{\\lim}(\\nabla_xg(x,\\phi)$ \n",
    "\n",
    "Donc $g(\\cdot, \\phi)$ est derivable sur R et $\\nabla_xg(x, \\phi) = \\left \\{\n",
    "\\begin{array} {}\n",
    "    0 & if \\, x \\le - \\frac{\\phi}{\\rho} \\\\\n",
    "    \\rho x + \\phi & if \\, x \\gt - \\frac{\\phi}{\\rho} \\\\\n",
    "\\end{array}\n",
    "\\right . = \\rho \\max (0, x+\\frac{\\phi}{\\rho})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même pour g comme fonction de $\\phi$ pour tout x. Par prolongement de la dérivée en $\\phi = -x \\rho$ on obtient la dérivabilité sur R de $g(x, \\cdot)$. \n",
    "\n",
    "Et $\\nabla_\\phi g(x, \\phi) = \\left \\{\n",
    "\\begin{array} {}\n",
    "    -\\frac{\\phi}{\\rho} & if \\, \\phi \\le - x{\\rho} \\\\\n",
    "    x & if \\, \\phi \\gt - x{\\rho} \\\\\n",
    "\\end{array}\n",
    "\\right . =\\max (-\\frac{\\phi}{\\rho}, x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $\\forall \\phi g_\\phi(x) = g(x, \\phi)$. On a $g_\\phi$ qui est derivable sur R et $g_\\phi'(x) = \\nabla_x g(x,\\phi) = \\rho \\max (0, x+\\frac{\\phi}{\\rho})$. On peut observer que $g_\\phi'$ est une fonction croissante sur R (c'est une fonction de x). Donc $g_\\phi$ est convexe $\\forall \\phi$.\n",
    "\n",
    "De meme soit $g_x(\\phi) = g(x, \\phi)$. On a de la même manière $g_x'$ qui est décroissante sur R. Donc $g_x$ est concave $\\forall x$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 2\n",
    "\n",
    "def nabla_x_g(x, phi):\n",
    "    return rho * np.maximum(np.zeros(x.shape), x + phi/rho)\n",
    "\n",
    "def nabla_phi_g(x, phi):\n",
    "    return np.maximum(-phi/rho, x)\n",
    "\n",
    "\n",
    "def compute_min_v_a_xi_L(phi, psi):\n",
    "    # on se fixe des conditions initiales pour minimiser le lagrangien\n",
    "    v = np.zeros((30,))\n",
    "    a = 0\n",
    "    xi = np.zeros((569,))\n",
    "    \n",
    "    dv = np.zeros((30,))\n",
    "    da = 1.5\n",
    "    dxi = np.zeros((569,))\n",
    "    \n",
    "    while np.sum(dv**2)+da**2+np.sum(dxi**2)>1:\n",
    "        x = 1-xi-np.dot(np.diag(y), np.dot(X, v) + a)\n",
    "        \n",
    "        #Calcul des gradients\n",
    "        dv = v - np.dot(np.dot(np.diag(y), X).T, nabla_x_g(x, psi))\n",
    "        da = -np.sum(y * nabla_x_g(x,psi))\n",
    "        dxi = c - nabla_x_g(-xi, phi) - nabla_x_g(x, psi)\n",
    "        \n",
    "        gamma = 1/750\n",
    "        v -= gamma * dv\n",
    "        a -= gamma * da\n",
    "        xi -= gamma * dxi\n",
    "        \n",
    "    return v, a, xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.5/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nabla_phi_L(v,a,xi,phi,psi):\n",
    "    return nabla_phi_g(-xi, phi)\n",
    "\n",
    "def nabla_psi_L(v,a,xi,phi,psi):\n",
    "    x = 1-xi-np.dot(np.diag(y), np.dot(X, v) + a)\n",
    "    return nabla_phi_g(x, psi)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4.6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagr_aug_method(N):\n",
    "    phi = 0\n",
    "    psi = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "        v,a,xi = compute_min_v_a_xi_L(phi,psi)\n",
    "        phi += rho * nabla_phi_g(-xi, phi)\n",
    "        x = 1-xi-np.dot(np.diag(y), np.dot(X, v) + a)\n",
    "        psi += rho * nabla_phi_g(x, psi)\n",
    "    return v,a,xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n"
     ]
    }
   ],
   "source": [
    "v,a,xi = lagr_aug_method(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.032168400716554"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(v,xi):\n",
    "    return 1/2 * np.sum(v**2) + c * np.sum(xi)\n",
    "f(v,xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Comparer les méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La methode du sous grandient est meilleure que la stochastique dans ce cas. En effet la stochastique est trop aléatoire. On pourrait peut etre envisager de faire une variante ou on utilise un sous esemble des données à chaque étapes de taille plus que 1 pour éviter les réalisations extrèmes.\n",
    "\n",
    "Et pour la méthode du lagrangien augmenté elle semble être la meilleure, mais elle demande bien plus de temps et de capacité de calculs que les deux autres !\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
